{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run \"./constants\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import glob\n",
    "\n",
    "def concat_and_filter(\n",
    "        download_dir: str = DIR_DOWNLOAD,\n",
    "        class_dict: str = CLASS_DICT\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "        Concatenates and filters data.\n",
    "        \n",
    "        This function reads parquet files from a specified directory, filters the data based on a provided class dictionary, and returns a pandas DataFrame.\n",
    "\n",
    "        Args:\n",
    "            download_dir (str): The directory from where the parquet files will be read. The default value is DIR_DOWNLOAD.\n",
    "            class_dict (str): A dictionary that maps class names to procedure codes. The default value is CLASS_DICT.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A pandas DataFrame that contains the filtered data.\n",
    "\n",
    "        Example:\n",
    "            Here is an example of how to use this function::\n",
    "\n",
    "                df = concat_and_filter(download_dir=\"my_directory\", class_dict={\"class1\": [\"code1\", \"code2\"]})\n",
    "    \"\"\"\n",
    "\n",
    "    all_paths = [f'{path}' for file_path in glob.glob(f\"{download_dir}/*.parquet\") for path in glob.glob(f'{file_path}/*.parquet')]\n",
    "\n",
    "    # Criando um DataFrame vazio para armazenar os resultados\n",
    "    final_filtered_df = pd.DataFrame()\n",
    "    print('Function Concat: Started')\n",
    "    for file_path in all_paths:\n",
    "        #print(file_path)\n",
    "        df = pd.read_parquet(file_path)\n",
    "\n",
    "        filtered_values = df[df['PA_PROC_ID'].isin([item for sublist in class_dict.values() for item in sublist])].copy()\n",
    "        \n",
    "        filtered_values['CLASSE'] = filtered_values.apply(lambda row: next((class_name for class_name, class_codes in class_dict.items() if row['PA_PROC_ID'] in class_codes), None), axis=1)\n",
    "\n",
    "        # Adding to the empty DataFrame\n",
    "        final_filtered_df = pd.concat([final_filtered_df, filtered_values], ignore_index=True)\n",
    "\n",
    "    # Creating columns: DATA_DOWNLOAD and DATA_PROCESSAMENTO.\n",
    "    #final_filtered_df['DATA_DOWNLOAD'] = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    final_filtered_df['DATA_DOWNLOAD'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    final_filtered_df['DATA_DOWNLOAD'] = pd.to_datetime(final_filtered_df['DATA_DOWNLOAD'])\n",
    "    final_filtered_df['DATA_PROCESSAMENTO'] = pd.to_datetime(final_filtered_df['PA_MVM'], format='%Y%m')\n",
    "    #final_filtered_df.to_csv(f'backup_datasus_{datetime.now().strftime(\"%d%m%y\")}.csv', index=False)\n",
    "    print('Function Concate has ended')\n",
    "    return final_filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = concat_and_filter()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
